{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc8b8c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all libraries will be imported in this block\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.mode.chained_assignment = None   #to hide settingwithcopy warning\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54a8c97",
   "metadata": {},
   "source": [
    "# Part-a  Using only Mother tongue column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42db80f",
   "metadata": {},
   "source": [
    "#### A test code to find constitution of c-17 dataframe that we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eded82f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''NOTE: In ques it has been asked to use Mother tongue. Though in C17 dataset it has not been explicitly mentioned\n",
    "that the column 'Total speaker of language' is mother tongue but after cross checking it with C16 dataset(there it\n",
    "has been explicitly mentioned column name is mother tongue) i found that no. of people is same in both of them for \n",
    "those columns. Hence C17 dataset column 'Total speaker of language' is the mother tongue language. So, here\n",
    "i will be using C17 dataset only'''\n",
    "\n",
    "test_df=pd.read_excel('Datasets/north/c-17-jammu & kashmir.XLSX')\n",
    "\n",
    "'''The dataframe columns are named as Unnamed:1,Unnamed:2,... .By cross check I found that the column having language \n",
    "name is \"Unnamed: 3\" and the number of speakers of that language is present in the next column \"Unnamed: 4\" in \n",
    "the same row number 5.'''\n",
    "# test_df['Unnamed: 3'].iloc[5] ---> this command gives output \"ASSAMESE\"  and the next column in same row gives 8340\n",
    "test_df=test_df[['Unnamed: 3','Unnamed: 4']]   \n",
    "\n",
    "'''now I have filtered this dataframe. It now has column1:language-name and column2:number-of-people-who-speak-that-language.\n",
    "I will now do this for each state/UT and sum up the number of speakers of every language in each region(NORTH,SOUTH,WEST,EAST,\n",
    " NORTH-EAST,CENTRAL)'''\n",
    "test_df=test_df   #no use of this line. Only used to hide previous comment being shown in output while running script\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac98f84",
   "metadata": {},
   "source": [
    "## Processing actual data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe0b552",
   "metadata": {},
   "source": [
    "### North Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a474db49",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Jammu & Kashmir'''\n",
    "my_df=pd.read_excel('Datasets/north/c-17-jammu & kashmir.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4']]\n",
    "\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "\n",
    "\n",
    "my_df=my_df.dropna()   #remove NaN rows\n",
    "my_df=my_df.loc[5: ,]  #remove useless rows \n",
    "#now this JK dataframe has languages and number of people who speak that language\n",
    "\n",
    "#Now I will make a dictionary so that searching for certain language will be quicker while summing up number of speakers of certain language in a region\n",
    "JK_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "#Now, I am going to do this for every state and UT\n",
    "'''Punjab'''\n",
    "my_df=pd.read_excel('Datasets/north/c-17-punjab.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4']]\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "my_df=my_df.dropna()   #remove NaN rows\n",
    "my_df=my_df.loc[5: ,]  #remove useless rows \n",
    "PN_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "'''Himachal pradesh'''\n",
    "my_df=pd.read_excel('Datasets/north/c-17-himachal pradesh.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4']]\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "my_df=my_df.dropna()   #remove NaN rows\n",
    "my_df=my_df.loc[5: ,]  #remove useless rows \n",
    "HP_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "'''Haryana'''\n",
    "my_df=pd.read_excel('Datasets/north/c-17-haryana.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4']]\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "my_df=my_df.dropna()   #remove NaN rows\n",
    "my_df=my_df.loc[5: ,]  #remove useless rows \n",
    "HR_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "'''Uttarakhand'''\n",
    "my_df=pd.read_excel('Datasets/north/c-17-uttarakhand.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4']]\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "my_df=my_df.dropna()   #remove NaN rows\n",
    "my_df=my_df.loc[5: ,]  #remove useless rows \n",
    "UK_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "\n",
    "'''Delhi'''\n",
    "my_df=pd.read_excel('Datasets/north/c-17-delhi.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4']]\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "my_df=my_df.dropna()   #remove NaN rows\n",
    "my_df=my_df.loc[5: ,]  #remove useless rows \n",
    "DL_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "\n",
    "'''Chandigarh'''\n",
    "my_df=pd.read_excel('Datasets/north/c-17-chandigarh.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4']]\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "my_df=my_df.dropna()   #remove NaN rows\n",
    "my_df=my_df.loc[5: ,]  #remove useless rows \n",
    "CN_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787b4754",
   "metadata": {},
   "source": [
    "### Creation of north_df which stores all languages spoken in this region with their respective number of speakers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d3b469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dataframe from each dictionary\n",
    "north_df1=pd.DataFrame(CN_dict.items(),columns=['language','speakers'])\n",
    "north_df2=pd.DataFrame(DL_dict.items(),columns=['language','speakers'])\n",
    "north_df3=pd.DataFrame(UK_dict.items(),columns=['language','speakers'])\n",
    "north_df4=pd.DataFrame(HR_dict.items(),columns=['language','speakers'])\n",
    "north_df5=pd.DataFrame(HP_dict.items(),columns=['language','speakers'])\n",
    "north_df6=pd.DataFrame(PN_dict.items(),columns=['language','speakers'])\n",
    "north_df7=pd.DataFrame(JK_dict.items(),columns=['language','speakers'])\n",
    "\n",
    "#taking union of those dataframes\n",
    "north_df=pd.merge(north_df1,north_df2,how='outer')\n",
    "north_df=pd.merge(north_df,north_df3,how='outer')\n",
    "north_df=pd.merge(north_df,north_df4,how='outer')\n",
    "north_df=pd.merge(north_df,north_df5,how='outer')\n",
    "north_df=pd.merge(north_df,north_df6,how='outer')\n",
    "north_df=pd.merge(north_df,north_df7,how='outer')\n",
    "\n",
    "'''After taking union there are multiple rows having language 'ASSAMESE'(similarly other languages also are present multiple times).\n",
    "And this north_df contains data from all the regions.So if I group it on basis of language column and find sum of\n",
    "'speakers' column within each group , I will get the total number of people who speak that language in whole region'''\n",
    "north_df=north_df.groupby(['language']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal if we store and re-load dataframe again\n",
    "north_df.to_csv('Datasets/north/north-df.csv')  #storing dataframe\n",
    "north_df=pd.read_csv('Datasets/north/north-df.csv')  #reloading the dataframe\n",
    "north_df=north_df.sort_values(by='speakers',ascending=False).head(30)  #taking only top three rows\n",
    "\n",
    "\n",
    "        #north_df[north_df['language']=='HINDI ']-->for cross checking whether my code gives correct number of hindi speakers    #It has been found that the string 'HINDI' is not present in the census but rather it is 'HINDI ' i.e. a 'space' at end. There are other such languages also."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eca0a5a",
   "metadata": {},
   "source": [
    "### West Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bfe2682",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Rajasthan'''\n",
    "RJ_df=pd.read_excel('Datasets/west/c-17-rajasthan.XLSX')\n",
    "RJ_df=RJ_df[['Unnamed: 3','Unnamed: 4']]\n",
    "RJ_df=RJ_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "RJ_df=RJ_df.dropna()   #remove NaN rows\n",
    "RJ_df=RJ_df.loc[5: ,]  #remove useless rows \n",
    "RJ_dict=dict(zip(RJ_df['language-name'] , RJ_df['speakers']))\n",
    "\n",
    "\n",
    "'''Gujarat'''\n",
    "GJ_df=pd.read_excel('Datasets/west/c-17-gujarat.XLSX')\n",
    "GJ_df=GJ_df[['Unnamed: 3','Unnamed: 4']]\n",
    "GJ_df=GJ_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "GJ_df=GJ_df.dropna()   #remove NaN rows\n",
    "GJ_df=GJ_df.loc[5: ,]  #remove useless rows \n",
    "GJ_dict=dict(zip(GJ_df['language-name'] , GJ_df['speakers']))\n",
    "\n",
    "'''Maharashtra'''\n",
    "MH_df=pd.read_excel('Datasets/west/c-17-maharashtra.XLSX')\n",
    "MH_df=MH_df[['Unnamed: 3','Unnamed: 4']]\n",
    "MH_df=MH_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "MH_df=MH_df.dropna()   #remove NaN rows\n",
    "MH_df=MH_df.loc[5: ,]  #remove useless rows \n",
    "MH_dict=dict(zip(MH_df['language-name'] , MH_df['speakers']))\n",
    "\n",
    "'''Goa'''\n",
    "GA_df=pd.read_excel('Datasets/west/c-17-goa.XLSX')\n",
    "GA_df=GA_df[['Unnamed: 3','Unnamed: 4']]\n",
    "GA_df=GA_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "GA_df=GA_df.dropna()   #remove NaN rows\n",
    "GA_df=GA_df.loc[5: ,]  #remove useless rows \n",
    "GA_dict=dict(zip(GA_df['language-name'] , GA_df['speakers']))\n",
    "\n",
    "'''Dadra & Nagar Haveli'''\n",
    "DNH_df=pd.read_excel('Datasets/west/c-17-dadra & nagar haveli.XLSX')\n",
    "DNH_df=DNH_df[['Unnamed: 3','Unnamed: 4']]\n",
    "DNH_df=DNH_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "DNH_df=DNH_df.dropna()   #remove NaN rows\n",
    "DNH_df=DNH_df.loc[5: ,]  #remove useless rows \n",
    "DNH_dict=dict(zip(DNH_df['language-name'] , DNH_df['speakers']))\n",
    "\n",
    "'''Daman & Diu'''\n",
    "DND_df=pd.read_excel('Datasets/west/c-17-daman & diu.XLSX')\n",
    "DND_df=DND_df[['Unnamed: 3','Unnamed: 4']]\n",
    "DND_df=DND_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "DND_df=DND_df.dropna()   #remove NaN rows\n",
    "DND_df=DND_df.loc[5: ,]  #remove useless rows \n",
    "DND_dict=dict(zip(DND_df['language-name'] , DND_df['speakers']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141c1f9b",
   "metadata": {},
   "source": [
    "### Creation of west_df which stores all languages spoken in this region with their respective number of speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c89ad497",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dataframe from each dictionary\n",
    "west_df1=pd.DataFrame(RJ_dict.items(),columns=['language','speakers'])\n",
    "west_df2=pd.DataFrame(GJ_dict.items(),columns=['language','speakers'])\n",
    "west_df3=pd.DataFrame(MH_dict.items(),columns=['language','speakers'])\n",
    "west_df4=pd.DataFrame(GA_dict.items(),columns=['language','speakers'])\n",
    "west_df5=pd.DataFrame(DNH_dict.items(),columns=['language','speakers'])\n",
    "west_df6=pd.DataFrame(DND_dict.items(),columns=['language','speakers'])\n",
    "\n",
    "\n",
    "#taking union of those dataframes\n",
    "west_df=pd.merge(west_df1,west_df2,how='outer')\n",
    "west_df=pd.merge(west_df,west_df3,how='outer')\n",
    "west_df=pd.merge(west_df,west_df4,how='outer')\n",
    "west_df=pd.merge(west_df,west_df5,how='outer')\n",
    "west_df=pd.merge(west_df,west_df6,how='outer')\n",
    "\n",
    "\n",
    "'''After taking union there are multiple rows having language 'ASSAMESE'(similarly other languages also are present multiple times).\n",
    "And this west_df contains data from all the regions.So if I group it on basis of language column and find sum of\n",
    "'speakers' column within each group , I will get the total number of people who speak that language in whole region'''\n",
    "west_df=west_df.groupby(['language']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal if we store and re-load dataframe again\n",
    "west_df.to_csv('Datasets/west/west-df.csv')  #storing dataframe\n",
    "west_df=pd.read_csv('Datasets/west/west-df.csv')  #reloading the dataframe\n",
    "\n",
    "west_df=west_df.sort_values(by='speakers',ascending=False).head(3)  #taking only top three rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc98387",
   "metadata": {},
   "source": [
    "### Central Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3cf86b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Madhya Pradesh'''\n",
    "MP_df=pd.read_excel('Datasets/central/c-17-madhya pradesh.XLSX')\n",
    "MP_df=MP_df[['Unnamed: 3','Unnamed: 4']]\n",
    "MP_df=MP_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "MP_df=MP_df.dropna()   #remove NaN rows\n",
    "MP_df=MP_df.loc[5: ,]  #remove useless rows \n",
    "MP_dict=dict(zip(MP_df['language-name'] , MP_df['speakers']))\n",
    "\n",
    "'''Uttar Pradesh'''\n",
    "UP_df=pd.read_excel('Datasets/central/c-17-uttar pradesh.XLSX')\n",
    "UP_df=UP_df[['Unnamed: 3','Unnamed: 4']]\n",
    "UP_df=UP_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "UP_df=UP_df.dropna()   #remove NaN rows\n",
    "UP_df=UP_df.loc[5: ,]  #remove useless rows \n",
    "UP_dict=dict(zip(UP_df['language-name'] , UP_df['speakers']))\n",
    "\n",
    "'''Chhattisgarh'''\n",
    "CG_df=pd.read_excel('Datasets/central/c-17-chhattisgarh.XLSX')\n",
    "CG_df=CG_df[['Unnamed: 3','Unnamed: 4']]\n",
    "CG_df=CG_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "CG_df=CG_df.dropna()   #remove NaN rows\n",
    "CG_df=CG_df.loc[5: ,]  #remove useless rows \n",
    "CG_dict=dict(zip(CG_df['language-name'] , CG_df['speakers']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6215ea2",
   "metadata": {},
   "source": [
    "### Creation of central_df which stores all languages spoken in this region with their respective number of speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f79f0e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dataframe from each dictionary\n",
    "central_df1=pd.DataFrame(MP_dict.items(),columns=['language','speakers'])\n",
    "central_df2=pd.DataFrame(UP_dict.items(),columns=['language','speakers'])\n",
    "central_df3=pd.DataFrame(CG_dict.items(),columns=['language','speakers'])\n",
    "\n",
    "\n",
    "\n",
    "#taking union of those dataframes\n",
    "central_df=pd.merge(central_df1,central_df2,how='outer')\n",
    "central_df=pd.merge(central_df,central_df3,how='outer')\n",
    "\n",
    "\n",
    "\n",
    "'''After taking union there are multiple rows having language 'ASSAMESE'(similarly other languages also are present multiple times).\n",
    "And this central_df contains data from all the regions.So if I group it on basis of language column and find sum of\n",
    "'speakers' column within each group , I will get the total number of people who speak that language in whole region'''\n",
    "central_df=central_df.groupby(['language']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal if we store and re-load dataframe again\n",
    "central_df.to_csv('Datasets/central/central-df.csv')  #storing dataframe\n",
    "central_df=pd.read_csv('Datasets/central/central-df.csv')  #reloading the dataframe\n",
    "\n",
    "central_df=central_df.sort_values(by='speakers',ascending=False).head(3)  #taking only top three rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6178a208",
   "metadata": {},
   "source": [
    "### East Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94e96b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Bihar'''\n",
    "BH_df=pd.read_excel('Datasets/east/c-17-bihar.XLSX')\n",
    "BH_df=BH_df[['Unnamed: 3','Unnamed: 4']]\n",
    "BH_df=BH_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "BH_df=BH_df.dropna()   #remove NaN rows\n",
    "BH_df=BH_df.loc[5: ,]  #remove useless rows \n",
    "BH_dict=dict(zip(BH_df['language-name'] , BH_df['speakers']))\n",
    "\n",
    "'''West Bengal'''\n",
    "WB_df=pd.read_excel('Datasets/east/c-17-west bengal.XLSX')\n",
    "WB_df=WB_df[['Unnamed: 3','Unnamed: 4']]\n",
    "WB_df=WB_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "WB_df=WB_df.dropna()   #remove NaN rows\n",
    "WB_df=WB_df.loc[5: ,]  #remove useless rows \n",
    "WB_dict=dict(zip(WB_df['language-name'] , WB_df['speakers']))\n",
    "\n",
    "'''Odisha'''\n",
    "#In census data the spelling is odisha and its actual code is OD but since in assignment question it is written OR so I will write its code as OR but spelling I will use Odisha \n",
    "OR_df=pd.read_excel('Datasets/east/c-17-odisha.XLSX')\n",
    "OR_df=OR_df[['Unnamed: 3','Unnamed: 4']]\n",
    "OR_df=OR_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "OR_df=OR_df.dropna()   #remove NaN rows\n",
    "OR_df=OR_df.loc[5: ,]  #remove useless rows \n",
    "OR_dict=dict(zip(OR_df['language-name'] , OR_df['speakers']))\n",
    "\n",
    "'''Jharkhand'''\n",
    "JH_df=pd.read_excel('Datasets/east/c-17-jharkhand.XLSX')\n",
    "JH_df=JH_df[['Unnamed: 3','Unnamed: 4']]\n",
    "JH_df=JH_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "JH_df=JH_df.dropna()   #remove NaN rows\n",
    "JH_df=JH_df.loc[5: ,]  #remove useless rows \n",
    "JH_dict=dict(zip(JH_df['language-name'] , JH_df['speakers']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa6ae5d",
   "metadata": {},
   "source": [
    "### Creation of east_df which stores all languages spoken in this region with their respective number of speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c4608d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dataframe from each dictionary\n",
    "east_df1=pd.DataFrame(BH_dict.items(),columns=['language','speakers'])\n",
    "east_df2=pd.DataFrame(WB_dict.items(),columns=['language','speakers'])\n",
    "east_df3=pd.DataFrame(OR_dict.items(),columns=['language','speakers'])\n",
    "east_df4=pd.DataFrame(JH_dict.items(),columns=['language','speakers'])\n",
    "\n",
    "\n",
    "#taking union of those dataframes\n",
    "east_df=pd.merge(east_df1,east_df2,how='outer')\n",
    "east_df=pd.merge(east_df,east_df3,how='outer')\n",
    "east_df=pd.merge(east_df,east_df4,how='outer')\n",
    "\n",
    "\n",
    "'''After taking union there are multiple rows having language 'ASSAMESE'(similarly other languages also are present multiple times).\n",
    "And this east_df contains data from all the regions.So if I group it on basis of language column and find sum of\n",
    "'speakers' column within each group , I will get the total number of people who speak that language in whole region'''\n",
    "east_df=east_df.groupby(['language']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal if we store and re-load dataframe again\n",
    "east_df.to_csv('Datasets/east/east-df.csv')  #storing dataframe\n",
    "east_df=pd.read_csv('Datasets/east/east-df.csv')  #reloading the dataframe\n",
    "\n",
    "east_df=east_df.sort_values(by='speakers',ascending=False).head(3)  #taking only top three rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06155fd",
   "metadata": {},
   "source": [
    "### South Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d426cc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Karnataka'''\n",
    "KA_df=pd.read_excel('Datasets/south/c-17-karnataka.XLSX')\n",
    "KA_df=KA_df[['Unnamed: 3','Unnamed: 4']]\n",
    "KA_df=KA_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "KA_df=KA_df.dropna()   #remove NaN rows\n",
    "KA_df=KA_df.loc[5: ,]  #remove useless rows \n",
    "KA_dict=dict(zip(KA_df['language-name'] , KA_df['speakers']))\n",
    "\n",
    "'''Andhra Pradesh'''\n",
    "AP_df=pd.read_excel('Datasets/south/c-17-andhra pradesh.XLSX')\n",
    "AP_df=AP_df[['Unnamed: 3','Unnamed: 4']]\n",
    "AP_df=AP_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "AP_df=AP_df.dropna()   #remove NaN rows\n",
    "AP_df=AP_df.loc[5: ,]  #remove useless rows \n",
    "AP_dict=dict(zip(AP_df['language-name'] , AP_df['speakers']))\n",
    "\n",
    "'''Tamil Nadu'''\n",
    "TN_df=pd.read_excel('Datasets/south/c-17-tamil nadu.XLSX')\n",
    "TN_df=TN_df[['Unnamed: 3','Unnamed: 4']]\n",
    "TN_df=TN_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "TN_df=TN_df.dropna()   #remove NaN rows\n",
    "TN_df=TN_df.loc[5: ,]  #remove useless rows \n",
    "TN_dict=dict(zip(TN_df['language-name'] , TN_df['speakers']))\n",
    "\n",
    "'''Kerala'''\n",
    "KL_df=pd.read_excel('Datasets/south/c-17-kerala.XLSX')\n",
    "KL_df=KL_df[['Unnamed: 3','Unnamed: 4']]\n",
    "KL_df=KL_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "KL_df=KL_df.dropna()   #remove NaN rows\n",
    "KL_df=KL_df.loc[5: ,]  #remove useless rows \n",
    "KL_dict=dict(zip(KL_df['language-name'] , KL_df['speakers']))\n",
    "\n",
    "'''Lakshadweep'''\n",
    "LD_df=pd.read_excel('Datasets/south/c-17-lakshadweep.XLSX')\n",
    "LD_df=LD_df[['Unnamed: 3','Unnamed: 4']]\n",
    "LD_df=LD_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "LD_df=LD_df.dropna()   #remove NaN rows\n",
    "LD_df=LD_df.loc[5: ,]  #remove useless rows \n",
    "LD_dict=dict(zip(LD_df['language-name'] , LD_df['speakers']))\n",
    "\n",
    "'''Puducherry'''\n",
    "PY_df=pd.read_excel('Datasets/south/c-17-puducherry.XLSX')\n",
    "PY_df=PY_df[['Unnamed: 3','Unnamed: 4']]\n",
    "PY_df=PY_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "PY_df=PY_df.dropna()   #remove NaN rows\n",
    "PY_df=PY_df.loc[5: ,]  #remove useless rows \n",
    "PY_dict=dict(zip(PY_df['language-name'] , PY_df['speakers']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334388d3",
   "metadata": {},
   "source": [
    "### Creation of south_df which stores all languages spoken in this region with their respective number of speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b27c19d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dataframe from each dictionary\n",
    "south_df1=pd.DataFrame(KA_dict.items(),columns=['language','speakers'])\n",
    "south_df2=pd.DataFrame(AP_dict.items(),columns=['language','speakers'])\n",
    "south_df3=pd.DataFrame(TN_dict.items(),columns=['language','speakers'])\n",
    "south_df4=pd.DataFrame(KL_dict.items(),columns=['language','speakers'])\n",
    "south_df5=pd.DataFrame(PY_dict.items(),columns=['language','speakers'])\n",
    "south_df6=pd.DataFrame(LD_dict.items(),columns=['language','speakers'])\n",
    "\n",
    "\n",
    "#taking union of those dataframes\n",
    "south_df=pd.merge(south_df1,south_df2,how='outer')\n",
    "south_df=pd.merge(south_df,south_df3,how='outer')\n",
    "south_df=pd.merge(south_df,south_df4,how='outer')\n",
    "south_df=pd.merge(south_df,south_df5,how='outer')\n",
    "south_df=pd.merge(south_df,south_df6,how='outer')\n",
    "\n",
    "\n",
    "'''After taking union there are multiple rows having language 'ASSAMESE'(similarly other languages also are present multiple times).\n",
    "And this south_df contains data from all the regions.So if I group it on basis of language column and find sum of\n",
    "'speakers' column within each group , I will get the total number of people who speak that language in whole region'''\n",
    "south_df=south_df.groupby(['language']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal if we store and re-load dataframe again\n",
    "south_df.to_csv('Datasets/south/south-df.csv')  #storing dataframe\n",
    "south_df=pd.read_csv('Datasets/south/south-df.csv')  #reloading the dataframe\n",
    "\n",
    "south_df=south_df.sort_values(by='speakers',ascending=False).head(3)  #taking only top three rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6095b5a8",
   "metadata": {},
   "source": [
    "### North-East Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e668b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Assam'''\n",
    "AS_df=pd.read_excel('Datasets/north-east/c-17-assam.XLSX')\n",
    "AS_df=AS_df[['Unnamed: 3','Unnamed: 4']]\n",
    "AS_df=AS_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "AS_df=AS_df.dropna()   #remove NaN rows\n",
    "AS_df=AS_df.loc[5: ,]  #remove useless rows \n",
    "AS_dict=dict(zip(AS_df['language-name'] , AS_df['speakers']))\n",
    "\n",
    "'''Sikkim'''\n",
    "SK_df=pd.read_excel('Datasets/north-east/c-17-sikkim.XLSX')\n",
    "SK_df=SK_df[['Unnamed: 3','Unnamed: 4']]\n",
    "SK_df=SK_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "SK_df=SK_df.dropna()   #remove NaN rows\n",
    "SK_df=SK_df.loc[5: ,]  #remove useless rows \n",
    "SK_dict=dict(zip(SK_df['language-name'] , SK_df['speakers']))\n",
    "\n",
    "\n",
    "'''Meghalaya'''\n",
    "MG_df=pd.read_excel('Datasets/north-east/c-17-meghalaya.XLSX')\n",
    "MG_df=MG_df[['Unnamed: 3','Unnamed: 4']]\n",
    "MG_df=MG_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "MG_df=MG_df.dropna()   #remove NaN rows\n",
    "MG_df=MG_df.loc[5: ,]  #remove useless rows \n",
    "MG_dict=dict(zip(MG_df['language-name'] , MG_df['speakers']))\n",
    "\n",
    "\n",
    "'''Tripura'''\n",
    "TR_df=pd.read_excel('Datasets/north-east/c-17-tripura.XLSX')\n",
    "TR_df=TR_df[['Unnamed: 3','Unnamed: 4']]\n",
    "TR_df=TR_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "TR_df=TR_df.dropna()   #remove NaN rows\n",
    "TR_df=TR_df.loc[5: ,]  #remove useless rows \n",
    "TR_dict=dict(zip(TR_df['language-name'] , TR_df['speakers']))\n",
    "\n",
    "\n",
    "'''Arunachal Pradesh'''\n",
    "AR_df=pd.read_excel('Datasets/north-east/c-17-arunachal pradesh.XLSX')\n",
    "AR_df=AR_df[['Unnamed: 3','Unnamed: 4']]\n",
    "AR_df=AR_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "AR_df=AR_df.dropna()   #remove NaN rows\n",
    "AR_df=AR_df.loc[5: ,]  #remove useless rows \n",
    "AR_dict=dict(zip(AR_df['language-name'] , AR_df['speakers']))\n",
    "\n",
    "\n",
    "'''Manipur'''\n",
    "MN_df=pd.read_excel('Datasets/north-east/c-17-manipur.XLSX')\n",
    "MN_df=MN_df[['Unnamed: 3','Unnamed: 4']]\n",
    "MN_df=MN_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "MN_df=MN_df.dropna()   #remove NaN rows\n",
    "MN_df=MN_df.loc[5: ,]  #remove useless rows \n",
    "MN_dict=dict(zip(MN_df['language-name'] , MN_df['speakers']))\n",
    "\n",
    "\n",
    "'''nagaland'''\n",
    "NG_df=pd.read_excel('Datasets/north-east/c-17-nagaland.XLSX')\n",
    "NG_df=NG_df[['Unnamed: 3','Unnamed: 4']]\n",
    "NG_df=NG_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "NG_df=NG_df.dropna()   #remove NaN rows\n",
    "NG_df=NG_df.loc[5: ,]  #remove useless rows \n",
    "NG_dict=dict(zip(NG_df['language-name'] , NG_df['speakers']))\n",
    "\n",
    "\n",
    "'''Mizoram'''\n",
    "MZ_df=pd.read_excel('Datasets/north-east/c-17-mizoram.XLSX')\n",
    "MZ_df=MZ_df[['Unnamed: 3','Unnamed: 4']]\n",
    "MZ_df=MZ_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "MZ_df=MZ_df.dropna()   #remove NaN rows\n",
    "MZ_df=MZ_df.loc[5: ,]  #remove useless rows \n",
    "MZ_dict=dict(zip(MZ_df['language-name'] , MZ_df['speakers']))\n",
    "\n",
    "\n",
    "'''Andaman & Nicobar'''\n",
    "AN_df=pd.read_excel('Datasets/north-east/c-17-andaman & nicobar islands.XLSX')\n",
    "AN_df=AN_df[['Unnamed: 3','Unnamed: 4']]\n",
    "AN_df=AN_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "AN_df=AN_df.dropna()   #remove NaN rows\n",
    "AN_df=AN_df.loc[5: ,]  #remove useless rows \n",
    "AN_dict=dict(zip(AN_df['language-name'] , AN_df['speakers']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592a5494",
   "metadata": {},
   "source": [
    "### Creation of north_east_df which stores all languages spoken in this region with their respective number of speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d6e0b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dataframe from each dictionary\n",
    "north_east_df1=pd.DataFrame(AS_dict.items(),columns=['language','speakers'])\n",
    "north_east_df2=pd.DataFrame(SK_dict.items(),columns=['language','speakers'])\n",
    "north_east_df3=pd.DataFrame(MG_dict.items(),columns=['language','speakers'])\n",
    "north_east_df4=pd.DataFrame(TR_dict.items(),columns=['language','speakers'])\n",
    "north_east_df5=pd.DataFrame(AR_dict.items(),columns=['language','speakers'])\n",
    "north_east_df6=pd.DataFrame(MN_dict.items(),columns=['language','speakers'])\n",
    "north_east_df7=pd.DataFrame(NG_dict.items(),columns=['language','speakers'])\n",
    "north_east_df8=pd.DataFrame(MZ_dict.items(),columns=['language','speakers'])\n",
    "north_east_df9=pd.DataFrame(AN_dict.items(),columns=['language','speakers'])\n",
    "\n",
    "\n",
    "#taking union of those dataframes\n",
    "#note that this merge will remove duplicates when both the language name and no-of-speakers will be same in two states. We don't want this. But here that situation will not arise because matching of language and no-of-speakers of two states is nearly impossible\n",
    "north_east_df=pd.merge(north_east_df1,north_east_df2,how='outer')\n",
    "north_east_df=pd.merge(north_east_df,north_east_df3,how='outer')\n",
    "north_east_df=pd.merge(north_east_df,north_east_df4,how='outer')\n",
    "north_east_df=pd.merge(north_east_df,north_east_df5,how='outer')\n",
    "north_east_df=pd.merge(north_east_df,north_east_df6,how='outer')\n",
    "north_east_df=pd.merge(north_east_df,north_east_df7,how='outer')\n",
    "north_east_df=pd.merge(north_east_df,north_east_df8,how='outer')\n",
    "north_east_df=pd.merge(north_east_df,north_east_df9,how='outer')\n",
    "\n",
    "\n",
    "'''After taking union there are multiple rows having language 'ASSAMESE'(similarly other languages also are present multiple times).\n",
    "And this north_east_df contains data from all the regions.So if I group it on basis of language column and find sum of\n",
    "'speakers' column within each group , I will get the total number of people who speak that language in whole region'''\n",
    "north_east_df=north_east_df.groupby(['language']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal if we store and re-load dataframe again\n",
    "north_east_df.to_csv('Datasets/north-east/north-east-df.csv')  #storing dataframe\n",
    "north_east_df=pd.read_csv('Datasets/north-east/north-east-df.csv')  #reloading the dataframe\n",
    "\n",
    "north_east_df=north_east_df.sort_values(by='speakers',ascending=False).head(3)  #taking only top three rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ae3d1a",
   "metadata": {},
   "source": [
    "### Creation of output file region-india.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d28f7b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_india_df=pd.DataFrame(columns=['region','language-1','language-2','language-3'])\n",
    "\n",
    "region_india_df=region_india_df.append({'region':'North','language-1':north_df['language'].iloc[0],'language-2':north_df['language'].iloc[1],'language-3':north_df['language'].iloc[2]},ignore_index=True)\n",
    "\n",
    "region_india_df=region_india_df.append({'region':'West','language-1':west_df['language'].iloc[0],'language-2':west_df['language'].iloc[1],'language-3':west_df['language'].iloc[2]},ignore_index=True)\n",
    "\n",
    "region_india_df=region_india_df.append({'region':'Central','language-1':central_df['language'].iloc[0],'language-2':central_df['language'].iloc[1],'language-3':central_df['language'].iloc[2]},ignore_index=True)\n",
    "\n",
    "region_india_df=region_india_df.append({'region':'East','language-1':east_df['language'].iloc[0],'language-2':east_df['language'].iloc[1],'language-3':east_df['language'].iloc[2]},ignore_index=True)\n",
    "\n",
    "region_india_df=region_india_df.append({'region':'South','language-1':south_df['language'].iloc[0],'language-2':south_df['language'].iloc[1],'language-3':south_df['language'].iloc[2]},ignore_index=True)\n",
    "\n",
    "region_india_df=region_india_df.append({'region':'North-East','language-1':north_east_df['language'].iloc[0],'language-2':north_east_df['language'].iloc[1],'language-3':north_east_df['language'].iloc[2]},ignore_index=True)\n",
    "\n",
    "\n",
    "region_india_df.to_csv('output files/region-india-a.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26b18bc",
   "metadata": {},
   "source": [
    "# \n",
    "# part-b  Using mother tongue + 2nd lang + 3rd lang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ff8505",
   "metadata": {},
   "source": [
    "### North Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14772177",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Jammu & Kashmir'''\n",
    "my_df=pd.read_excel('Datasets/north/c-17-jammu & kashmir.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "#now this dataframe has languages and number of people who speak that language\n",
    "#Now I will make a dictionary so that searching for certain language will be quicker while summing up number of speakers of certain language in a region\n",
    "JK_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Now, I am going to do this for every state and UT\n",
    "'''Punjab'''\n",
    "my_df=pd.read_excel('Datasets/north/c-17-punjab.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "PN_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "\n",
    "\n",
    "'''Himachal pradesh'''\n",
    "my_df=pd.read_excel('Datasets/north/c-17-himachal pradesh.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "HP_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "\n",
    "\n",
    "'''Haryana'''\n",
    "my_df=pd.read_excel('Datasets/north/c-17-haryana.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "HR_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "\n",
    "\n",
    "'''Uttarakhand'''\n",
    "my_df=pd.read_excel('Datasets/north/c-17-uttarakhand.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "UK_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "\n",
    "\n",
    "'''Delhi'''\n",
    "my_df=pd.read_excel('Datasets/north/c-17-delhi.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "DL_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "\n",
    "\n",
    "'''Chandigarh'''\n",
    "my_df=pd.read_excel('Datasets/north/c-17-chandigarh.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "\n",
    "CN_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc02db5",
   "metadata": {},
   "source": [
    "### Creation of north_df which stores all languages spoken in this region with their respective number of speakers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce4353ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dataframe from each dictionary\n",
    "north_df1=pd.DataFrame(CN_dict.items(),columns=['language','speakers'])\n",
    "north_df2=pd.DataFrame(DL_dict.items(),columns=['language','speakers'])\n",
    "north_df3=pd.DataFrame(UK_dict.items(),columns=['language','speakers'])\n",
    "north_df4=pd.DataFrame(HR_dict.items(),columns=['language','speakers'])\n",
    "north_df5=pd.DataFrame(HP_dict.items(),columns=['language','speakers'])\n",
    "north_df6=pd.DataFrame(PN_dict.items(),columns=['language','speakers'])\n",
    "north_df7=pd.DataFrame(JK_dict.items(),columns=['language','speakers'])\n",
    "\n",
    "#taking union of those dataframes\n",
    "north_df=pd.merge(north_df1,north_df2,how='outer')\n",
    "north_df=pd.merge(north_df,north_df3,how='outer')\n",
    "north_df=pd.merge(north_df,north_df4,how='outer')\n",
    "north_df=pd.merge(north_df,north_df5,how='outer')\n",
    "north_df=pd.merge(north_df,north_df6,how='outer')\n",
    "north_df=pd.merge(north_df,north_df7,how='outer')\n",
    "\n",
    "'''After taking union there are multiple rows having language 'ASSAMESE'(similarly other languages also are present multiple times).\n",
    "And this north_df contains data from all the regions.So if I group it on basis of language column and find sum of\n",
    "'speakers' column within each group , I will get the total number of people who speak that language in whole region'''\n",
    "north_df=north_df.groupby(['language']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal if we store and re-load dataframe again\n",
    "north_df.to_csv('Datasets/north/north-df.csv')  #storing dataframe\n",
    "north_df=pd.read_csv('Datasets/north/north-df.csv')  #reloading the dataframe\n",
    "north_df=north_df.sort_values(by='speakers',ascending=False).head(30)  #taking only top three rows\n",
    "\n",
    "\n",
    "        #north_df[north_df['language']=='HINDI ']-->for cross checking whether my code gives correct number of hindi speakers    #It has been found that the string 'HINDI' is not present in the census but rather it is 'HINDI ' i.e. a 'space' at end. There are other such languages also."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea78ff4",
   "metadata": {},
   "source": [
    "### West Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3efb39ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Rajasthan'''\n",
    "my_df=pd.read_excel('Datasets/west/c-17-rajasthan.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "RJ_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "\n",
    "'''Gujarat'''\n",
    "my_df=pd.read_excel('Datasets/west/c-17-gujarat.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "GJ_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "'''Maharashtra'''\n",
    "my_df=pd.read_excel('Datasets/west/c-17-maharashtra.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "MH_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "'''Goa'''\n",
    "my_df=pd.read_excel('Datasets/west/c-17-goa.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "GA_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "'''Dadra & Namyr Haveli'''\n",
    "my_df=pd.read_excel('Datasets/west/c-17-dadra & nagar haveli.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "DNH_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "'''Daman & Diu'''\n",
    "my_df=pd.read_excel('Datasets/west/c-17-daman & diu.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "DND_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4192d0e",
   "metadata": {},
   "source": [
    "### Creation of west_df which stores all languages spoken in this region with their respective number of speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d494896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dataframe from each dictionary\n",
    "west_df1=pd.DataFrame(RJ_dict.items(),columns=['language','speakers'])\n",
    "west_df2=pd.DataFrame(GJ_dict.items(),columns=['language','speakers'])\n",
    "west_df3=pd.DataFrame(MH_dict.items(),columns=['language','speakers'])\n",
    "west_df4=pd.DataFrame(GA_dict.items(),columns=['language','speakers'])\n",
    "west_df5=pd.DataFrame(DNH_dict.items(),columns=['language','speakers'])\n",
    "west_df6=pd.DataFrame(DND_dict.items(),columns=['language','speakers'])\n",
    "\n",
    "\n",
    "#taking union of those dataframes\n",
    "west_df=pd.merge(west_df1,west_df2,how='outer')\n",
    "west_df=pd.merge(west_df,west_df3,how='outer')\n",
    "west_df=pd.merge(west_df,west_df4,how='outer')\n",
    "west_df=pd.merge(west_df,west_df5,how='outer')\n",
    "west_df=pd.merge(west_df,west_df6,how='outer')\n",
    "\n",
    "\n",
    "'''After taking union there are multiple rows having language 'ASSAMESE'(similarly other languages also are present multiple times).\n",
    "And this west_df contains data from all the regions.So if I group it on basis of language column and find sum of\n",
    "'speakers' column within each group , I will get the total number of people who speak that language in whole region'''\n",
    "west_df=west_df.groupby(['language']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal if we store and re-load dataframe again\n",
    "west_df.to_csv('Datasets/west/west-df.csv')  #storing dataframe\n",
    "west_df=pd.read_csv('Datasets/west/west-df.csv')  #reloading the dataframe\n",
    "\n",
    "west_df=west_df.sort_values(by='speakers',ascending=False).head(3)  #taking only top three rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd9e72a",
   "metadata": {},
   "source": [
    "### Central Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25749d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Madhya Pradesh'''\n",
    "my_df=pd.read_excel('Datasets/central/c-17-madhya pradesh.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "MP_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "'''Uttar Pradesh'''\n",
    "my_df=pd.read_excel('Datasets/central/c-17-uttar pradesh.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "UP_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "'''Chhattisgarh'''\n",
    "my_df=pd.read_excel('Datasets/central/c-17-chhattisgarh.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "CG_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51134670",
   "metadata": {},
   "source": [
    "### Creation of central_df which stores all languages spoken in this region with their respective number of speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8d6c7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dataframe from each dictionary\n",
    "central_df1=pd.DataFrame(MP_dict.items(),columns=['language','speakers'])\n",
    "central_df2=pd.DataFrame(UP_dict.items(),columns=['language','speakers'])\n",
    "central_df3=pd.DataFrame(CG_dict.items(),columns=['language','speakers'])\n",
    "\n",
    "\n",
    "\n",
    "#taking union of those dataframes\n",
    "central_df=pd.merge(central_df1,central_df2,how='outer')\n",
    "central_df=pd.merge(central_df,central_df3,how='outer')\n",
    "\n",
    "\n",
    "\n",
    "'''After taking union there are multiple rows having language 'ASSAMESE'(similarly other languages also are present multiple times).\n",
    "And this central_df contains data from all the regions.So if I group it on basis of language column and find sum of\n",
    "'speakers' column within each group , I will get the total number of people who speak that language in whole region'''\n",
    "central_df=central_df.groupby(['language']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal if we store and re-load dataframe again\n",
    "central_df.to_csv('Datasets/central/central-df.csv')  #storing dataframe\n",
    "central_df=pd.read_csv('Datasets/central/central-df.csv')  #reloading the dataframe\n",
    "\n",
    "central_df=central_df.sort_values(by='speakers',ascending=False).head(3)  #taking only top three rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea27cc98",
   "metadata": {},
   "source": [
    "### East Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e2e862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Bihar'''\n",
    "my_df=pd.read_excel('Datasets/east/c-17-bihar.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "BH_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "'''West Bengal'''\n",
    "my_df=pd.read_excel('Datasets/east/c-17-west bengal.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "WB_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "'''Odisha'''\n",
    "#In census data the spelling is odisha and its actual code is OD but since in assignment question it is written OR so I will write its code as OR but spelling I will use Odisha \n",
    "my_df=pd.read_excel('Datasets/east/c-17-odisha.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "OR_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "'''Jharkhand'''\n",
    "my_df=pd.read_excel('Datasets/east/c-17-jharkhand.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "JH_dict=dict(zip(my_df['language-name'] , my_df['speakers']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d972fa7",
   "metadata": {},
   "source": [
    "### Creation of east_df which stores all languages spoken in this region with their respective number of speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c6faebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dataframe from each dictionary\n",
    "east_df1=pd.DataFrame(BH_dict.items(),columns=['language','speakers'])\n",
    "east_df2=pd.DataFrame(WB_dict.items(),columns=['language','speakers'])\n",
    "east_df3=pd.DataFrame(OR_dict.items(),columns=['language','speakers'])\n",
    "east_df4=pd.DataFrame(JH_dict.items(),columns=['language','speakers'])\n",
    "\n",
    "\n",
    "#taking union of those dataframes\n",
    "east_df=pd.merge(east_df1,east_df2,how='outer')\n",
    "east_df=pd.merge(east_df,east_df3,how='outer')\n",
    "east_df=pd.merge(east_df,east_df4,how='outer')\n",
    "\n",
    "\n",
    "'''After taking union there are multiple rows having language 'ASSAMESE'(similarly other languages also are present multiple times).\n",
    "And this east_df contains data from all the regions.So if I group it on basis of language column and find sum of\n",
    "'speakers' column within each group , I will get the total number of people who speak that language in whole region'''\n",
    "east_df=east_df.groupby(['language']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal if we store and re-load dataframe again\n",
    "east_df.to_csv('Datasets/east/east-df.csv')  #storing dataframe\n",
    "east_df=pd.read_csv('Datasets/east/east-df.csv')  #reloading the dataframe\n",
    "\n",
    "east_df=east_df.sort_values(by='speakers',ascending=False).head(3)  #taking only top three rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e784b42",
   "metadata": {},
   "source": [
    "### South Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d9fba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Karnataka'''\n",
    "my_df=pd.read_excel('Datasets/south/c-17-karnataka.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "KA_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "'''Andhra Pradesh'''\n",
    "my_df=pd.read_excel('Datasets/south/c-17-andhra pradesh.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "AP_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "'''Tamil Nadu'''\n",
    "my_df=pd.read_excel('Datasets/south/c-17-tamil nadu.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "TN_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "'''Kerala'''\n",
    "my_df=pd.read_excel('Datasets/south/c-17-kerala.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "KL_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "'''Lakshadweep'''\n",
    "my_df=pd.read_excel('Datasets/south/c-17-lakshadweep.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "LD_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "'''Puducherry'''\n",
    "my_df=pd.read_excel('Datasets/south/c-17-puducherry.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index() \n",
    "PY_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a786af05",
   "metadata": {},
   "source": [
    "### Creation of south_df which stores all languages spoken in this region with their respective number of speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93f64533",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dataframe from each dictionary\n",
    "south_df1=pd.DataFrame(KA_dict.items(),columns=['language','speakers'])\n",
    "south_df2=pd.DataFrame(AP_dict.items(),columns=['language','speakers'])\n",
    "south_df3=pd.DataFrame(TN_dict.items(),columns=['language','speakers'])\n",
    "south_df4=pd.DataFrame(KL_dict.items(),columns=['language','speakers'])\n",
    "south_df5=pd.DataFrame(PY_dict.items(),columns=['language','speakers'])\n",
    "south_df6=pd.DataFrame(LD_dict.items(),columns=['language','speakers'])\n",
    "\n",
    "\n",
    "#taking union of those dataframes\n",
    "south_df=pd.merge(south_df1,south_df2,how='outer')\n",
    "south_df=pd.merge(south_df,south_df3,how='outer')\n",
    "south_df=pd.merge(south_df,south_df4,how='outer')\n",
    "south_df=pd.merge(south_df,south_df5,how='outer')\n",
    "south_df=pd.merge(south_df,south_df6,how='outer')\n",
    "\n",
    "\n",
    "'''After taking union there are multiple rows having language 'ASSAMESE'(similarly other languages also are present multiple times).\n",
    "And this south_df contains data from all the regions.So if I group it on basis of language column and find sum of\n",
    "'speakers' column within each group , I will get the total number of people who speak that language in whole region'''\n",
    "south_df=south_df.groupby(['language']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal if we store and re-load dataframe again\n",
    "south_df.to_csv('Datasets/south/south-df.csv')  #storing dataframe\n",
    "south_df=pd.read_csv('Datasets/south/south-df.csv')  #reloading the dataframe\n",
    "\n",
    "south_df=south_df.sort_values(by='speakers',ascending=False).head(3)  #taking only top three rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db695e2",
   "metadata": {},
   "source": [
    "### North-East Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85faafdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Assam'''\n",
    "my_df=pd.read_excel('Datasets/north-east/c-17-assam.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "AS_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "'''Sikkim'''\n",
    "my_df=pd.read_excel('Datasets/north-east/c-17-sikkim.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "SK_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "\n",
    "'''Meghalaya'''\n",
    "my_df=pd.read_excel('Datasets/north-east/c-17-meghalaya.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "MG_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "\n",
    "'''Tripura'''\n",
    "my_df=pd.read_excel('Datasets/north-east/c-17-tripura.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "TR_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "\n",
    "'''Arunachal Pradesh'''\n",
    "my_df=pd.read_excel('Datasets/north-east/c-17-arunachal pradesh.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "AR_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "\n",
    "'''Manipur'''\n",
    "my_df=pd.read_excel('Datasets/north-east/c-17-manipur.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "MN_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "\n",
    "'''nagaland'''\n",
    "my_df=pd.read_excel('Datasets/north-east/c-17-nagaland.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "NG_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "\n",
    "'''Mizoram'''\n",
    "my_df=pd.read_excel('Datasets/north-east/c-17-mizoram.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "MZ_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n",
    "\n",
    "\n",
    "'''Andaman & Nicobar'''\n",
    "my_df=pd.read_excel('Datasets/north-east/c-17-andaman & nicobar islands.XLSX')\n",
    "my_df=my_df[['Unnamed: 3','Unnamed: 4','Unnamed: 8','Unnamed: 9','Unnamed: 13','Unnamed: 14']]\n",
    "#performing union operation of mother tongue, 2nd lang and 3rd lang column\n",
    "my_df=my_df.rename(columns={'Unnamed: 3':'language-name' , 'Unnamed: 4':'speakers'})\n",
    "test_df1=my_df[['Unnamed: 8','Unnamed: 9']]\n",
    "test_df1.rename(columns={'Unnamed: 8':'language-name','Unnamed: 9':'speakers'},inplace=True)\n",
    "test_df2=my_df[['Unnamed: 13','Unnamed: 14']]\n",
    "test_df2.rename(columns={'Unnamed: 13':'language-name','Unnamed: 14':'speakers'},inplace=True)\n",
    "my_df=my_df[['language-name','speakers']]\n",
    "#remove NaN rows\n",
    "my_df.dropna(inplace=True)\n",
    "test_df1.dropna(inplace=True)\n",
    "test_df2.dropna(inplace=True)\n",
    "#remove useless rows \n",
    "my_df=my_df.loc[5:,]\n",
    "test_df1=test_df1.loc[6:,]\n",
    "test_df2=test_df2.loc[7:,]\n",
    "my_df=my_df.append(test_df1)\n",
    "my_df=my_df.append(test_df2)\n",
    "my_df=my_df.groupby(['language-name']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal by reset_index() function\n",
    "my_df=my_df.reset_index()\n",
    "AN_dict=dict(zip(my_df['language-name'] , my_df['speakers']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14332b2e",
   "metadata": {},
   "source": [
    "### Creation of north_east_df which stores all languages spoken in this region with their respective number of speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9237204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dataframe from each dictionary\n",
    "north_east_df1=pd.DataFrame(AS_dict.items(),columns=['language','speakers'])\n",
    "north_east_df2=pd.DataFrame(SK_dict.items(),columns=['language','speakers'])\n",
    "north_east_df3=pd.DataFrame(MG_dict.items(),columns=['language','speakers'])\n",
    "north_east_df4=pd.DataFrame(TR_dict.items(),columns=['language','speakers'])\n",
    "north_east_df5=pd.DataFrame(AR_dict.items(),columns=['language','speakers'])\n",
    "north_east_df6=pd.DataFrame(MN_dict.items(),columns=['language','speakers'])\n",
    "north_east_df7=pd.DataFrame(NG_dict.items(),columns=['language','speakers'])\n",
    "north_east_df8=pd.DataFrame(MZ_dict.items(),columns=['language','speakers'])\n",
    "north_east_df9=pd.DataFrame(AN_dict.items(),columns=['language','speakers'])\n",
    "\n",
    "\n",
    "#taking union of those dataframes\n",
    "#note that this merge will remove duplicates when both the language name and no-of-speakers will be same in two states. We don't want this. But here that situation will not arise because matching of language and no-of-speakers of two states is nearly impossible\n",
    "north_east_df=pd.merge(north_east_df1,north_east_df2,how='outer')\n",
    "north_east_df=pd.merge(north_east_df,north_east_df3,how='outer')\n",
    "north_east_df=pd.merge(north_east_df,north_east_df4,how='outer')\n",
    "north_east_df=pd.merge(north_east_df,north_east_df5,how='outer')\n",
    "north_east_df=pd.merge(north_east_df,north_east_df6,how='outer')\n",
    "north_east_df=pd.merge(north_east_df,north_east_df7,how='outer')\n",
    "north_east_df=pd.merge(north_east_df,north_east_df8,how='outer')\n",
    "north_east_df=pd.merge(north_east_df,north_east_df9,how='outer')\n",
    "\n",
    "\n",
    "'''After taking union there are multiple rows having language 'ASSAMESE'(similarly other languages also are present multiple times).\n",
    "And this north_east_df contains data from all the regions.So if I group it on basis of language column and find sum of\n",
    "'speakers' column within each group , I will get the total number of people who speak that language in whole region'''\n",
    "north_east_df=north_east_df.groupby(['language']).sum()  #since groupby is applied, the structure of dataframe has been changed. It will be restored to normal if we store and re-load dataframe again\n",
    "north_east_df.to_csv('Datasets/north-east/north-east-df.csv')  #storing dataframe\n",
    "north_east_df=pd.read_csv('Datasets/north-east/north-east-df.csv')  #reloading the dataframe\n",
    "\n",
    "north_east_df=north_east_df.sort_values(by='speakers',ascending=False).head(3)  #taking only top three rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309f98b6",
   "metadata": {},
   "source": [
    "### Creation of output file region-india.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c95f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_india_df=pd.DataFrame(columns=['region','language-1','language-2','language-3'])\n",
    "\n",
    "region_india_df=region_india_df.append({'region':'North','language-1':north_df['language'].iloc[0],'language-2':north_df['language'].iloc[1],'language-3':north_df['language'].iloc[2]},ignore_index=True)\n",
    "\n",
    "region_india_df=region_india_df.append({'region':'West','language-1':west_df['language'].iloc[0],'language-2':west_df['language'].iloc[1],'language-3':west_df['language'].iloc[2]},ignore_index=True)\n",
    "\n",
    "region_india_df=region_india_df.append({'region':'Central','language-1':central_df['language'].iloc[0],'language-2':central_df['language'].iloc[1],'language-3':central_df['language'].iloc[2]},ignore_index=True)\n",
    "\n",
    "region_india_df=region_india_df.append({'region':'East','language-1':east_df['language'].iloc[0],'language-2':east_df['language'].iloc[1],'language-3':east_df['language'].iloc[2]},ignore_index=True)\n",
    "\n",
    "region_india_df=region_india_df.append({'region':'South','language-1':south_df['language'].iloc[0],'language-2':south_df['language'].iloc[1],'language-3':south_df['language'].iloc[2]},ignore_index=True)\n",
    "\n",
    "region_india_df=region_india_df.append({'region':'North-East','language-1':north_east_df['language'].iloc[0],'language-2':north_east_df['language'].iloc[1],'language-3':north_east_df['language'].iloc[2]},ignore_index=True)\n",
    "\n",
    "\n",
    "region_india_df.to_csv('output files/region-india-b.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5610ff56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
